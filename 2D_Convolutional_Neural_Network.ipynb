{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 1 - Creating 2D-Convolutional Layer"
      ],
      "metadata": {
        "id": "ceREbGEG8r2S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "PDOY-_Q_-guZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class SimpleConv2d():\n",
        "  \n",
        "  def __init__(self, F, C, FH, FW, P, S, initializer=None,optimizer=None,activation=None):\n",
        "      self.P = P\n",
        "      self.S = S\n",
        "      self.initializer = initializer\n",
        "      self.activation = activation\n",
        "\n",
        "      self.W = self.initializer.W(F,C,FH,FW)\n",
        "      self.B = self.initializer.B(F)\n",
        "  \n",
        "  def output_shape2d(self,H,W,PH,PW,FH,FW,SH,SW):\n",
        "      OH = (H +2*PH -FH)/SH +1\n",
        "      OW = (W +2*PW - FW)/SW +1\n",
        "      return int(OH),int(OW)\n",
        "  \n",
        "  def forward(self, X):\n",
        "      self.X = X\n",
        "      N,C,H,W = self.X.shape\n",
        "      F,C,FH,FW = self.W.shape\n",
        "      OH,OW = self.output_shape2d(H,W,self.P,self.P,FH,FW,self.S,self.S)\n",
        "      self.params = N,C,H,W,F,FH,FW,OH,OW\n",
        "\n",
        "      A = np.zeros([N,F,OH,OW])\n",
        "      self.X.pad = np.pad(self.X,((0,0),(0,0),(self.P,self.P),(self.P,self.P)))\n",
        "\n",
        "      for n in range(N):\n",
        "          for ch in range(F):\n",
        "              for row in range(0,H,self.S):\n",
        "                  for col in range(0,W,self.S):\n",
        "                      A[n,ch,row,col] = \\\n",
        "                      np.sum(self.X_pad[n,:,row:row+FH,col:col+FH]\n",
        "                              +self.W[ch,:,:,:]) \\\n",
        "                      +self.B[ch]\n",
        "      return self.activation.forward(A)\n",
        "\n",
        "  def backward(self, dZ):\n",
        "      dA = self.activation.backward(dZ)\n",
        "      N,C,H,W,F,FH,FW,OH,OW = self.params\n",
        "\n",
        "      dZ = np.zeros(self.X_pad.shape)\n",
        "      self.dW = np.zeros(self.W.shape)\n",
        "      self.dB = np.zeros(self.B.shape)\n",
        "\n",
        "      for n in range(N):\n",
        "          for ch in range(F):\n",
        "              for row in range(OH):\n",
        "                  for col in range(OW):\n",
        "                      self.dW[ch,:,:,:] += dA[n,ch,row,col]*self.X_pad[n,:,row:row+FH,col:col+FW]\n",
        "      \n",
        "      for ch in range(F):\n",
        "          self.dB[ch] = np.sum(dA[:,ch,:,:])\n",
        "      \n",
        "      self = self.optimizer.update(self)\n",
        "      return dZ\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 2/3 - Experiments with 2D Conv. Layers & Output Size after 2DMC"
      ],
      "metadata": {
        "id": "OSg1JUBwMZ6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def output_shape2d(IH=5,IW=5,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1):\n",
        "    OH = (IH +2*PH -FH)/SH +1\n",
        "    OW = (IW +2*PW -FW)/SW +1\n",
        "    return int(OH),int(OW)"
      ],
      "metadata": {
        "id": "R2zIlGaWMZAx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_shape2d(IH=6,IW=6,PH=0,PW=0,FH=3,FW=3,SH=1,SW=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oxdhQ-LN9Ko",
        "outputId": "860552c0-1908-46a7-a935-e62f8377b35b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2DC Experiment"
      ],
      "metadata": {
        "id": "plIV0j2gOd88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N,C,H,W = (5,1,28,28)\n",
        "F,C,FH,FW = (4,1,3,3)\n",
        "\n",
        "S = 1\n",
        "P = 1\n",
        "\n",
        "OH,OW = output_shape2d(H,W,P,P,FH,FW,S,S)\n",
        "\n",
        "A = np.zeros([N,F,OH,OW])\n",
        "\n",
        "X_sample = X[0:N].reshape(N,C,H,W)\n",
        "X_pad = np.pad(X_sample,((0,0),(0,0),(P,P),(P,P)))\n",
        "W = np.ones([F,C,FH,FW])\n",
        "B = np.ones(F)\n",
        "\n",
        "for n in range(N):\n",
        "          for ch in range(F):\n",
        "              for row in range(0,H,S):\n",
        "                  for col in range(0,W,S):\n",
        "                      A[n,ch,row,col] = \\\n",
        "                      np.sum(X_pad[n,:,row:row+FH,col:col+FH]*W[ch,:,:,:]) +B[ch]\n",
        "\n",
        "print ('A.shape:', A.shape)"
      ],
      "metadata": {
        "id": "0SbyOc03Ocj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dA = np.ones(A.shape)\n",
        "\n",
        "dZ = np.zeros(X_pad.shape)\n",
        "dW = np.zeros(W.shape)\n",
        "dB = np.zeros(B.shape)\n",
        "\n",
        "for n in range(N):\n",
        "    for ch in range(F):\n",
        "        for row in range(0,H,S):\n",
        "            for col in range(0,W,S):\n",
        "                dZ[n,:,row:row+FH,col:col+FW] +=dA[n,ch,row,col]*W[ch,:,:,:]\n",
        "\n",
        "dl_rows = range(P),range(H+P,H+2*P,1)\n",
        "dl_cols = range(P),range(W+P,W+2*P,1)\n",
        "\n",
        "dZ = np.delete(dZ,dl_rows,axis=2)\n",
        "dZ = np.delete(dZ,dl_cols,axis=3)\n",
        "\n",
        "for n in range(N):\n",
        "          for ch in range(F):\n",
        "              for row in range(OH):\n",
        "                  for col in range(OW):\n",
        "                      dW[ch,:,:,:] +=dA[n,ch,row,col]*X_pad[n,:,row:row+FH,col:col+FW]\n",
        "\n",
        "for ch in range(F):\n",
        "    dB[ch] = np.sum(dA[:,ch,:,:])\n",
        "\n",
        "print('dZ.shape:',dZ.shape)\n",
        "print('dW.shape:',dW.shape)\n",
        "print('dB.shape:',dB.shape)"
      ],
      "metadata": {
        "id": "vWs05eZrR7cJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 4 - Creating a Maximum Pooling Layer"
      ],
      "metadata": {
        "id": "npg6oh4tVwm1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool2D():\n",
        "\n",
        "    def __init__(self,P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.Pindex = None\n",
        "    \n",
        "    def forward(self,A):\n",
        "        N,F,OH,OW = A.shape\n",
        "        PS = self.P\n",
        "        PH,PW = int(OH/PS),int(OW/PS)\n",
        "\n",
        "        self.params = N,F,OH,OW,PS,PH,PW\n",
        "\n",
        "        self.PA = np.zeros([N,F,PH,PW])\n",
        "        self.Pindex = np.zeros([N,F,PH,PW])\n",
        "\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        self.PA[n,ch,row,col] = \\\n",
        "                        np.max(A[n,ch,row*PS:row*PS+PS,col+PS:col*PS+PS])\n",
        "\n",
        "                        self.Pindex[n,ch,row,col] = \\\n",
        "                        np.argmax(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
        "        \n",
        "        return self.PA\n",
        "    \n",
        "    def backward(self,dA):\n",
        "        N,F,OH,OW,PS,PH,PW = self.params\n",
        "        dP = np.zeros([N,F,OH,OW])\n",
        "\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        idx = self.Pindex[n,ch,row,col]\n",
        "                        tmp = np.zeros((PS*PS))\n",
        "                        for i in range(PS*PS):\n",
        "                            if i ==idx:\n",
        "                                tmp[i] = dA[n,ch,row,col]\n",
        "                            else:\n",
        "                                tmp[i] = 0\n",
        "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "        return dP"
      ],
      "metadata": {
        "id": "e-ph7YZwVv4s"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JsCKwuKdQ63",
        "outputId": "1fa0324f-b558-4dc2-ae4e-4fb4b537870d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[3 4 2 1 5 2]\n",
            "   [2 6 1 7 1 4]\n",
            "   [0 3 1 6 2 7]\n",
            "   [7 0 7 5 4 0]\n",
            "   [4 8 0 2 5 0]\n",
            "   [3 3 5 0 7 5]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pooling = MaxPool2D(P=2)\n",
        "A = Pooling.forward(X)\n",
        "\n",
        "print(A.shape)\n",
        "print(A)"
      ],
      "metadata": {
        "id": "IpQ_KyFpeBzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Pooling.Pindex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDaJp9_TfE9p",
        "outputId": "a79993cf-fd96-47e4-ccd9-0b7d0cd546ef"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0., 0., 0.],\n",
              "         [0., 0., 0.],\n",
              "         [0., 0., 0.]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
        "print(dA)"
      ],
      "metadata": {
        "id": "Mwy0h-_QfReh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dZ = Pooling.backward(dA)\n",
        "print(dZ)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgMsH2ucf0pZ",
        "outputId": "4bfbc750-894f-4072-f19c-5331ab8b1205"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[1. 0. 1. 0. 1. 0.]\n",
            "   [0. 0. 0. 0. 0. 0.]\n",
            "   [1. 0. 1. 0. 1. 0.]\n",
            "   [0. 0. 0. 0. 0. 0.]\n",
            "   [1. 0. 1. 0. 1. 0.]\n",
            "   [0. 0. 0. 0. 0. 0.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem 5 - Creating An Average Pooling"
      ],
      "metadata": {
        "id": "9lbRmFgpgNPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AveragePool2D():\n",
        "\n",
        "    def __init__(self,P):\n",
        "        self.P = P\n",
        "        self.PA = None\n",
        "        self.Pindex = None\n",
        "    \n",
        "    def forward(self,A):\n",
        "        N,F,OH,OW = A.shape\n",
        "        PS = self.P\n",
        "        PH,PW = int(OH/PS),int(OW/PS)\n",
        "\n",
        "        self.params = N,F,OH,OW,PS,PH,PW\n",
        "\n",
        "        self.PA = np.zeros([N,F,PH,PW])\n",
        "\n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        self.PA[n,ch,row,col] = \\\n",
        "                        np.mean(A[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS])\n",
        "        return self.PA\n",
        "    \n",
        "    def backward(self,dA):\n",
        "\n",
        "        N,F,OH,PS,PH,PW = self.params\n",
        "        dP = np.zeros([N,F,OH,OW])\n",
        "        \n",
        "        for n in range(N):\n",
        "            for ch in range(F):\n",
        "                for row in range(PH):\n",
        "                    for col in range(PW):\n",
        "                        tmp = np.zeros((PS*PS))\n",
        "                        for i in range(PS*PS):\n",
        "                            tmp[i] = dA[n,ch,row,col]/(PS*PS)\n",
        "                        dP[n,ch,row*PS:row*PS+PS,col*PS:col*PS+PS] = tmp.reshape(PS,PS)\n",
        "        return dP"
      ],
      "metadata": {
        "id": "KRE7bfubgMR5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.random.randint(0,9,36).reshape(1,1,6,6)\n",
        "print(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WM9jcpp5jnBV",
        "outputId": "2be5269c-ad5d-482d-ac87-faccfbe04c4f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[4 2 2 3 0 5]\n",
            "   [2 5 3 4 0 5]\n",
            "   [0 3 3 4 5 5]\n",
            "   [0 6 1 0 4 4]\n",
            "   [6 3 7 8 1 7]\n",
            "   [0 0 7 1 2 1]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Pooling = AveragePool2D(P=2)\n",
        "A = Pooling.forward(X)\n",
        "\n",
        "print(A.shape)\n",
        "print(A)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw6Z_5y-tARr",
        "outputId": "0334c987-84de-40a0-a1b6-469ecbfb3041"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 1, 3, 3)\n",
            "[[[[3.25 3.   2.5 ]\n",
            "   [2.25 2.   4.5 ]\n",
            "   [2.25 5.75 2.75]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dA = np.random.randint(0,9,9).reshape(A.shape)\n",
        "print(dA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x087QvQdtVZQ",
        "outputId": "f2dcbe44-a339-407f-d46d-03bf8f0f81b1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[7 6 6]\n",
            "   [8 5 8]\n",
            "   [2 0 5]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dZ = Pooling.backward(dA)\n",
        "print(dZ)"
      ],
      "metadata": {
        "id": "f9fkqyH3tyZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 6 - Flatten"
      ],
      "metadata": {
        "id": "mJhuBb5yukfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Flatten:\n",
        "    def __init__(self,):\n",
        "        pass\n",
        "    def forward(self,X):\n",
        "        self.shape = X.shape\n",
        "        return X.reshape(len(X),-1)\n",
        "    \n",
        "    def backward(self,X):\n",
        "        return X.reshape(self.shape)"
      ],
      "metadata": {
        "id": "8uKW0ekpujuD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TEST = np.zeros([20,2,5,5])\n",
        "flt = Flatten()\n",
        "flat_forward = flt.forward(TEST)\n",
        "print('Forward_shape Display:', flat_forward.shape)\n",
        "print('Backward_shape Display:',flt.backward(flat_forward).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOU4i5c6wzB1",
        "outputId": "d828336f-ddfa-4d78-8481-6d9ecbf7b910"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forward_shape Display: (20, 50)\n",
            "Backward_shape Display: (20, 2, 5, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 7 - Training and Estimation"
      ],
      "metadata": {
        "id": "7rFz-DrIyE4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Scratch2dCNNClassifier():\n",
        "\n",
        "    def __init__(self, NN, CNN, n_epoch=5, n_batch=1, verbose = False):\n",
        "        self.n_epoch = n_epoch\n",
        "        self.n_batch = n_batch\n",
        "        self.verbose = verbose\n",
        "        self.log_loss = np.zeros(self.n_epoch)\n",
        "        self.log_acc = np.zeros(self.n_epoch)\n",
        "        self.NN = NN\n",
        "        self.CNN = CNN \n",
        "        \n",
        "    def loss_functin(self,y,yt):\n",
        "        delta = 1e-7\n",
        "        return -np.mean(yt*np.log(y+delta))\n",
        "    \n",
        "    def accuracy(self,Z,Y):\n",
        "        return accuracy_score(Y,Z)\n",
        "    \n",
        "    def fit(self, x,y, x_val=False, y_val=False):\n",
        "        for epoch in range(self.n_epoch):\n",
        "            get_mini_batch = GetMiniBatch(x, y, batch_size=self.n_batch)\n",
        "\n",
        "            self.loss = 0\n",
        "            for mini_x_train, mini_y_train in get_mini_batch:\n",
        "\n",
        "                forward_data = mini_x_train[:,np.newaxis,:,:]\n",
        "\n",
        "                for layer in range(len(self.CNN)):\n",
        "                    forward_data = self.CNN[layer].forward(forward_data)\n",
        "                \n",
        "                flt = Flatten()\n",
        "                forward_data = flt.forward(forward_data)\n",
        "\n",
        "                for layer in range(len(self.NN)):\n",
        "                    forward_data = self.NN[layer].forward(forward_data)\n",
        "                \n",
        "                Z = forward_data\n",
        "\n",
        "                backward_data = (Z - mini_y_train)/self.n_batch\n",
        "                for layer in range(len(self.NN)-1,-1,-1):\n",
        "                  backward_data = self.NN[layer].backward(backward_data)\n",
        "                \n",
        "                backward_data = flt.backward(backward_data)\n",
        "\n",
        "                for layer in (len(self.CNN)-1,-1,-1):\n",
        "                    backward_data = self.CNN[layer].backward(backward_data)\n",
        "                \n",
        "                self.loss += self.loss_function(Z,mini_y_train)\n",
        "            \n",
        "            self.log_loss[epoch] = self.loss/len(get_mini_batch)\n",
        "            self.log_acc[epoch] = self.accuracy(self.predict(x),np.argmax(y,axis=1))\n",
        "      \n",
        "    def predict(self, X):\n",
        "          predict_data = X[:,np.newaxis,:,:]\n",
        "\n",
        "          for layer in range(len(self.CNN)):\n",
        "              pred_data = self.CNN[layer].forward(pred_data)\n",
        "          \n",
        "          flt = Flatten()\n",
        "          pred_data = flt.forward(pred_data)\n",
        "\n",
        "          for layer in range(len(self.NN)):\n",
        "              pred_data = self.NN[layer].forward(pred_data)\n",
        "          \n",
        "          return np.argmax(pred_data,axis=1)"
      ],
      "metadata": {
        "id": "BLTM2L-zyDza"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NN = {0:FC(784, 400, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "      1:FC(400, 200, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "      2:FC(200, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),      \n",
        "      }"
      ],
      "metadata": {
        "id": "GBND4WLh8LqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CNN = {0:SimpleConv2d(F=10, C=1, FH=3, FW=3, P=1, S=1,\n",
        "                      initializer=SimpleInitializerConv2d(),\n",
        "                      optimizer=SGD(),\n",
        "                      activation=ReLU())}"
      ],
      "metadata": {
        "id": "pnL-5VFP_PvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn1 = Scratch2dCNNClassifier(NN=NN,CNN=CNN,n_epoch=10,n_batch=200,verbose=False)\n",
        "\n",
        "cnn1.fit(x_train[0:1000],y_train[0:1000])"
      ],
      "metadata": {
        "id": "VyARBCAbAPOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = cnn1.predict(x_valid[0:100])\n",
        "\n",
        "accuracy = accuracy_score(np.argmax(y_valid[0:100],axis=1), y_pred)\n",
        "print('accuracy:{:.3f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "medHx_5JAt1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizing the Loss Function"
      ],
      "metadata": {
        "id": "aMRRURTNB3GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as plt\n",
        "\n",
        "plt.rcParams[\"font.size\"] = 20\n",
        "fig=plt.subplots(figsize=(16,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('LOSS PLOT')\n",
        "plt.plot(cnn1.log_loss,'bo--')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('ACCURACY PLOT')\n",
        "plt.plot(cnn1.log_acc,'rs--');"
      ],
      "metadata": {
        "id": "F1E1yQ4WB1jA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 8 - LeNet\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "6AlTSrmTDxap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LeNetCNN = {0:SimpleConv2d(F=6, C=1, FH=5, FW=5, P=2, S=1,\n",
        "                      initializer=SimpleInitializerConv2d(),\n",
        "                      optimizer=SGD(),\n",
        "                      activation=ReLU()),\n",
        "            1:MaxPool2D(P=2),\n",
        "            2:SimpleConv2d(F=16, C=6, FH=5, FW=5, P=2, S=1,\n",
        "                      initializer=SimpleInitializerConv2d(),\n",
        "                      optimizer=SGD(),\n",
        "                      activation=ReLU()),\n",
        "            3:MaxPool2D(P=2),}\n",
        "\n",
        "LeNetNN = {0:FC(784, 120, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "            1:FC(120, 84, HeInitializer(), AdaGrad(0.01), ReLU()),\n",
        "            2:FC(84, 10, SimpleInitializer(0.01), AdaGrad(0.01), Softmax()),}\n",
        "\n",
        "\n",
        "LeNet = Scratch2dCNNClassifier(NN=LeNetNN,CNN=LeNetCNN,\n",
        "                               n_epoch=10,n_batch=20,verbose=False)\n",
        "\n",
        "LeNet.fit(x_train[0:1000],y_train[0:1000])     "
      ],
      "metadata": {
        "id": "nF1f4hXxDwsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_LeNet = LeNet.predict(x_valid[0:100])\n",
        "\n",
        "accuracy = accuracy_score(np.argmax(y_valid[0:1000],axis=1), y_pred_LeNet)\n",
        "print('accuracy:{:.3f}'.format(accuracy))"
      ],
      "metadata": {
        "id": "Ath-G4AVGLxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as plt\n",
        "\n",
        "plt.rcParams[\"font.size\"] = 20\n",
        "fig=plt.subplots(figsize=(16,6))\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('LOSS PLOT')\n",
        "plt.plot(LeNet.log_loss,'bo--')\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('ACCURACY PLOT')\n",
        "plt.plot(LeNet.log_acc,'rs--');"
      ],
      "metadata": {
        "id": "HOps5-BTG6zu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 9 - Survey of Well-Known image recognition models "
      ],
      "metadata": {
        "id": "4lP-Da3pJ0tA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Introduction\n",
        "#The human brain can easily recognize and distinguish the objects in an image. For instance, given the image of a cat and dog, within nanoseconds, we distinguish the two and our brain perceives this difference. In case a machine mimics this behavior, it is as close to Artificial Intelligence we can get. Subsequently, the field of Computer Vision aims to mimic the human vision system – and there have been numerous milestones that have broken the barriers in this regard.\n",
        "\"The rapid developments in Computer Vision, and by extension – image classification has been further accelerated by the advent of Transfer Learning. To put it simply, Transfer learning allows us to use a pre-existing model, trained on a huge dataset, for our own tasks. Consequently, reducing the cost of training new deep learning models and since the datasets have been vetted, we can be assured of the quality.In Image Classification, there are some very popular datasets that are used across research, industry, and hackathons. The following are some of the prominent ones:\"\n",
        "•\tImageNet\n",
        "•\tCIFAR\n",
        "•\tMNIST\n",
        "\n",
        "\n",
        "##Pre-Trained Models for Image Classification \n",
        "•\tVGG-16\n",
        "•\tInceptionv3\n",
        "•\tResNet50\n",
        "•\tEfficientNet\n",
        "\n",
        "#1. Very Deep Convolutional Networks for Large-Scale Image Recognition (VGG-16)\n",
        "\"The VGG-16 is one of the most popular pre-trained models for image classification. Introduced in the famous ILSVRC 2014 Conference, it was and remains THE model to beat even today. Developed at the Visual Graphics Group at the University of Oxford, VGG-16 beat the then standard of AlexNet and was quickly adopted by researchers and the industry for their image Classification Tasks.\"\n",
        "\n",
        "#2. Inceptionv3\n",
        "\"While researching for this article – one thing was clear. The year 2014 has been iconic in terms of the development of really popular pre-trained models for Image Classification. While the above VGG-16 secured the 2nd rank in that years’ ILSVRC, the 1st rank was secured by none other than Google – via its model GoogLeNet or Inception as it is now later called as.The original paper proposed the Inceptionv1 Model. At only 7 million parameters, it was much smaller than the then prevalent models like VGG and AlexNet. Adding to it a lower error rate, you can see why it was a breakthrough model. Not only this, but the major innovation in this paper was also another breakthrough – the Inception Module.\"\"\n",
        "\n",
        "#3. ResNet50\n",
        "\"Just like Inceptionv3, ResNet50 is not the first model coming from the ResNet family. The original model was called the Residual net or ResNet and was another milestone in the CV domain back in 2015.The main motivation behind this model was to avoid poor accuracy as the model went on to become deeper. Additionally, if you are familiar with Gradient Descent, you would have come across the Vanishing Gradient issue – the ResNet model aimed to tackle this issue as well. Here is the architecture of the earliest variant: ResNet34(ResNet50 also follows a similar technique with just more layers)\"\n",
        "\n",
        "#4. EfficientNet\n",
        "\"We finally come to the latest model amongst these 4 that have caused waves in this domain and of course, it is from Google. In EfficientNet, the authors propose a new Scaling method called Compound Scaling. The long and short of it is this: The earlier models like ResNet follow the conventional approach of scaling the dimensions arbitrarily and by adding up more and more layers.However, the paper proposes that if we scale the dimensions by a fixed amount at the same time and do so uniformly, we achieve much better performance. The scaling coefficients can be in fact decided by the user.Though this scaling technique can be used for any CNN-based model, the authors started off with their own baseline model called EfficientNetB0:\"\"\n",
        "\n",
        "##https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n",
        "\n"
      ],
      "metadata": {
        "id": "-qbpC2poJzub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 10 - Calculating the Output Size"
      ],
      "metadata": {
        "id": "UXmkTSkHLCCu"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X1tFRNMiLBVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 11 - Survey on Filter Size\n",
        "\n",
        "1. why are 3*3 filters commonly used instead of larger ones such as 7**7?\n",
        "- Using a 3x3 filter expresses most information about the image across all the channels while keeping the size of the convolutions layers consistent with the size of the image (zero padding allows us to achieve this).\n",
        "\n",
        "\n",
        "\n",
        "2. What is the effect of a 1*1 filter with no height or width direction?\n",
        "- A 1 x 1 Convolution is a convolution with some special properties in that it can be used for dimensionality reduction, efficient low dimensional embeddings, and applying non-linearity after convolutions. It maps an input pixel with all its channels to an output pixel which can be squeezed to a desired output depth."
      ],
      "metadata": {
        "id": "ExdWthxyNtrb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qA62E_1hNs1m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}