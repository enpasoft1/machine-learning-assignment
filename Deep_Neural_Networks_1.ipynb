{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "8Ftu2kLSgbLe",
        "outputId": "de946434-e3b9-41c8-ae71-c3449ea16967"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x = np.arange(-2, 2, 0.02)\n",
        "\n",
        "sigmoid = 1./(1+np.exp(-x))\n",
        "tanh = (np.exp(x)-np.exp(-x))/(np.exp(x)+np.exp(-x))\n",
        "relu = np.max([np.zeros(len(x)), x], axis=0)\n",
        "\n",
        "plt.plot(x, sigmoid)\n",
        "plt.plot(x, tanh)\n",
        "plt.plot(x, relu)\n",
        "\n",
        "plt.xlabel('x Axis/Line')\n",
        "plt.ylabel('activation Axis')\n",
        "plt.legend(['Sigmoid', 'Tanh', 'Relu'])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK3cvhyukayD"
      },
      "source": [
        "Building Perceptron with sigmoid Activation in TensorFlow 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBDLL7m0imET"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def perceptron(input_dim):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(1, input_dim=input_dim, activation='sigmoid'))\n",
        "    return model\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3lDiOjWm0lz"
      },
      "source": [
        "Using the Summary() method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r6oa1mPmaSe",
        "outputId": "bd9c0aa7-2ada-4256-ad4c-7ff63cf8baa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 6         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6\n",
            "Trainable params: 6\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "my_perceptron = perceptron(input_dim=5)\n",
        "\n",
        "my_perceptron.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nikhjsqrJnn"
      },
      "source": [
        "Multi Layered Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbHTqSYynnhK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def mlp(input_dim):\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(3, input_dim=input_dim, activation='sigmoid'))\n",
        "    model.add(tf.keras.layers.Dense(4, activation='sigmoid'))\n",
        "    model.add(tf.keras.layers.Dense(4, activation='sigmoid'))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTo3da5ayLx9",
        "outputId": "c4f8b10b-a615-4688-b61f-d9735e65fd4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 1 - "
      ],
      "metadata": {
        "id": "M0Bgcxbkyt-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "class FC:\n",
        "    def _init_(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "        self.B = initializer.B(self.n_nodes2)\n",
        "        self.optimizer = optimizer\n",
        "        self.MW = 0\n",
        "        self.MB = 0\n",
        "\n",
        "    def forward(self,x):\n",
        "        self.Z = x\n",
        "        self.A = x @ self.W + self.B\n",
        "        return self.A\n",
        "    \n",
        "    def backward(self, dA):\n",
        "        self.dB = np.sum(dA, axis=0)\n",
        "        self.dW = self.Z.T @ dA\n",
        "        self.dZ = dA @ self.W.T\n",
        "        self = self.optimizer.update(self)\n",
        "        return self.dZ"
      ],
      "metadata": {
        "id": "_hTHWks7ys_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0cOWrUK15dRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 2 - Initialization Method"
      ],
      "metadata": {
        "id": "ztISXuu85bOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleInitializer:\n",
        "\n",
        "    def _init_(self, sigma):\n",
        "        self.sigma = sigma\n",
        "    \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        W = self.sigma * np.random(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "iCjTvLN_5ahy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 3"
      ],
      "metadata": {
        "id": "1r_YOBMaKTg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SGD:\n",
        "\n",
        "    def _init_(self, lr):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, layer):\n",
        "        layer.W -= self.lr * layer.dW / len(layer.Z)\n",
        "        layer.B -= self.lr * layer.dB / len(layer.Z)\n",
        "        return layer"
      ],
      "metadata": {
        "id": "l_iObvDEKSyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 4 - ACtivation Functions"
      ],
      "metadata": {
        "id": "sR3A9-x5LWKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Sigmoid:\n",
        "\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        Z = 1 / (1 + np.exp(-self.A))\n",
        "        return Z\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * ((1 / (1 + np.exp(-self.A))) - (1 / (1 + np.exp(-self.A)))**2)\n",
        "        return dA"
      ],
      "metadata": {
        "id": "GWshmuHWLVkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tanh:\n",
        "\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        Z = np.tanh(self.A)\n",
        "        return Z\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * (1 - np.tanh(self.A)**2)\n",
        "        return dA"
      ],
      "metadata": {
        "id": "-63n2xS2MW98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class softmax:\n",
        "\n",
        "    def forward(self, A):\n",
        "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, Z, y):\n",
        "        dA = Z - y\n",
        "        loss = - np.sum(y * np.log(Z)) / len(y)\n",
        "        return dA, loss"
      ],
      "metadata": {
        "id": "G83F4MqIM76N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 5\n"
      ],
      "metadata": {
        "id": "INw0ZG0iPIrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReLU:\n",
        "\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        Z = np.maximum(0, A)\n",
        "        return Z\n",
        "\n",
        "    def backward(self, dZ):\n",
        "      dA = dZ * np.where(self.A > 0, 1, 0)\n",
        "      return dA"
      ],
      "metadata": {
        "id": "ulgBXCAiPHs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 6 - Initial Weight Value"
      ],
      "metadata": {
        "id": "46fyxnj2Poi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XavierInitializer:\n",
        "\n",
        "    def _init_(self, sigma):\n",
        "        _ = sigma\n",
        "    \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.sigma = 1 / np.sqrt(n_nodes1)\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "GBQCo5lyPn1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HeInitializer:\n",
        "\n",
        "    def _init_(self, sigma):\n",
        "        _ = sigma\n",
        "    \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.sigma = np.sqrt(2 / n_nodes1)\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B"
      ],
      "metadata": {
        "id": "cj5BMSkRQoiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 7 - Optimization Method"
      ],
      "metadata": {
        "id": "Xcq3a3MRRVQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaGrad:\n",
        "\n",
        "    def _init_(self, lr):\n",
        "        self.lr = lr\n",
        "\n",
        "    def update(self, layer):\n",
        "        layer.HW += layer.dW + layer.dW\n",
        "        layer.HB += layer.dB + layer.dB\n",
        "        delta = len-7\n",
        "        layer.W -= self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
        "        layer.B -= self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
        "        return layer"
      ],
      "metadata": {
        "id": "qVourw-7RLy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 8 - Class Completion"
      ],
      "metadata": {
        "id": "3Iwo3i9HSLbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GetMiniBatch:\n",
        "\n",
        "    def _init_(self, x, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(x.shape[0]))\n",
        "        self._x = x[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(x.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "    def _len_(self):\n",
        "        return self._stop\n",
        "    \n",
        "    def _getitem_(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._x[p0:p1], self._y[p0:p1]\n",
        "\n",
        "    def _iter_(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    \n",
        "    def _next_(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._x[p0:p1], self._y[p0:p1]\n"
      ],
      "metadata": {
        "id": "DQomHrDdSKgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20\n",
        "        self.n_features = 784\n",
        "        self.n_nodes1 = 400\n",
        "        self.n_nodes2 = 200\n",
        "        self.n_output = 10\n",
        "        self.sigma = 0.02\n",
        "        self.lr = 0.5\n",
        "        self.epoch = epoch\n",
        "        self.optimizer = optimizer\n",
        "        self.initializer = initializer\n",
        "        self.activater = activater\n",
        "\n",
        "    def fit(self, x, y, x_val=None, y_val=None):\n",
        "        self.loss_train = []\n",
        "        self.loss_val = []\n",
        "        optimizer = self.optimizer(self.lr)\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "        self.activation1 = self.activater()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "        self.activation2 = self.activater()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "        self.activation3 = softmax()\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(x, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_x, mini_y in get_mini_batch:\n",
        "                A1 = self.FC1.forward(mini_x)\n",
        "                Z1 = self.activation1.forward(A1)\n",
        "                A2 = self.FC2.forward(Z1)\n",
        "                Z2 = self.activation2.forward(A2)\n",
        "                #print(Z2.shape)\n",
        "                A3 = self.FC3.forward(Z2)\n",
        "                Z3 = self.activation3.forward(A3)\n",
        "                dA3, loss = self.activation3.backward(Z3, mini_y)\n",
        "                dZ2 = self.FC3.backward(dA3)\n",
        "                dA2 = self.activation2.backward(dZ2)\n",
        "                dZ1 = self.FC2.backward(dA2)\n",
        "                dA1 = self.activation1.backward(dZ1)\n",
        "                dZ0 = self.FC1.backward(dA1)\n",
        "              \n",
        "            if self.verbose:\n",
        "                A1 = self.FC1.forward(x)\n",
        "                Z1 = self.activation1.forward(A1)\n",
        "                A2 = self.FC2.forward(Z1)\n",
        "                Z2 = self.activation2.forward(A2)\n",
        "                A3 = self.FC3.forward(Z2)\n",
        "                Z3 = self.activation3.forward(A3)\n",
        "                self.loss_train.append(self.activation3.backward(Z3, y)[1])\n",
        "\n",
        "                if x_val is not None:\n",
        "                    A1 = self.FC1.forward(x_val)\n",
        "                    Z1 = self.activation1.forward(A1)\n",
        "                    A2 = self.FC2.forward(Z1)\n",
        "                    Z2 = self.activation2.forward(A2)\n",
        "                    A3 = self.FC3.forward(Z2)\n",
        "                    Z3 = self.activation3.forward(A3)\n",
        "                    self.loss_val.append(self.activation3.backward(Z3, y_val)[1])\n",
        "\n",
        "    def predict(self, x):\n",
        "        A1 = self.FC1.forward(x)\n",
        "        Z1 = self.activation1.forward(A1)\n",
        "        A2 = self.FC2.forward(Z1)\n",
        "        Z2 = self.activation2.forward(A2)\n",
        "        A3 = self.FC3.forward(Z2)\n",
        "        Z3 = self.activation3.forward(A3)\n",
        "        return np.argmax(Z3, axis=1)"
      ],
      "metadata": {
        "id": "79MPcIsIVj_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem 9 - Learning & Estimation"
      ],
      "metadata": {
        "id": "n1QPUNeygXiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(-1, 784)\n",
        "x_test = x_test.reshape(-1, 784)\n",
        "\n",
        "x_train = x_train.astype(np.float)\n",
        "x_test = x_test.astype(np.float)\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdX_aa-GgQmn",
        "outputId": "526a260b-df7d-40f0-b0de-408f1d64785e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-27b4c89056b1>:4: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x_train = x_train.astype(np.float)\n",
            "<ipython-input-19-27b4c89056b1>:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x_test = x_test.astype(np.float)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)"
      ],
      "metadata": {
        "id": "CppQGfO21k61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_val[:, np.newaxis])"
      ],
      "metadata": {
        "id": "_0gbKYHE2cPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN = ScratchDeepNeuralNetrowkClassifier(verbose=True, epoch=10, optimizer=AdaGrad, initializer=HeInitializer, activater=ReLU)\n",
        "\n",
        "SDNN.fit(x_train, y_train_one_hot, x_val, y_test_one_hot)"
      ],
      "metadata": {
        "id": "B_wpaSSF3HxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = SDNN.predict(x_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "79DtWrjr4PWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(list(range(1, SDNN.epoch+1)), SDNN.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN.epoch+1)), SDNN.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN.epoch+1)));"
      ],
      "metadata": {
        "id": "uPVo9K_J4a-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier_4():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20\n",
        "        self.n_features = 784\n",
        "        self.n_nodes1 = 400\n",
        "        self.n_nodes2 = 200\n",
        "        self.n_nodes3 = 150\n",
        "        self.n_output = 10\n",
        "        self.sigma = 0.02\n",
        "        self.lr = 0.5\n",
        "        self.epoch = epoch\n",
        "        self.optimizer = optimizer\n",
        "        self.initializer = initializer\n",
        "        self.activater = activater\n",
        "\n",
        "    def fit(self, x, y, x_val=None, y_val=None):\n",
        "        self.loss_train = []\n",
        "        self.loss_val = []\n",
        "        optimizer = self.optimizer(self.lr)\n",
        "\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "        self.activation1 = self.activater()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "        self.activation2 = self.activater()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_nodes3, self.initializer(self.sigma), optimizer)\n",
        "        self.activation3 = self.activater()\n",
        "        self.FC4 = FC(self.n_nodes3, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "        self.activation4 = softmax()\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(x, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_x, mini_y in get_mini_batch:\n",
        "                self.forward(mini_x)\n",
        "                self.backward(mini_y)\n",
        "            \n",
        "            if self.verbose:\n",
        "                self.forward(x)\n",
        "                self.loss_train.append(self.activation4.backward(self.Z4, y)[1])\n",
        "\n",
        "                if x_val is not None:\n",
        "                    self.forward(x_val)\n",
        "                    self.loss_val.append(self.activation4.backward(self.Z4, y_val)[1])\n",
        "        \n",
        "        def forward(self, x):\n",
        "                A1 = self.FC1.forward(x)\n",
        "                Z1 = self.activation1.forward(A1)\n",
        "                A2 = self.FC2.forward(Z1)\n",
        "                Z2 = self.activation2.forward(A2)\n",
        "                A3 = self.FC3.forward(Z2)\n",
        "                Z3 = self.activation3.forward(A3)\n",
        "                A4 = self.FC4.forward(Z3)\n",
        "                self.Z4 = self.activation4.forward(A4)\n",
        "\n",
        "    def backward(self,y):\n",
        "                dA4, self.loss = self.activation4.backward(self.Z4, y)\n",
        "                dZ3 = self.FC4.backward(dA4)\n",
        "                dA3 = self.activation3.backward(dZ3)\n",
        "                dZ2 = self.FC3.backward(dA3)\n",
        "                dA2 = self.activation2.backward(dZ2)\n",
        "                dZ1 = self.FC2.backward(dA2)\n",
        "                dA1 = self.activation1.backward(dZ1)\n",
        "                dZ0 = self.FC1.backward(dA1)\n",
        "\n",
        "    def predict(self, x):\n",
        "        self.forward(x)\n",
        "        return np.argmax(self.Z4, axis=1)"
      ],
      "metadata": {
        "id": "v6Y9iIgN7JKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN4 = ScratchDeepNeuralNetrowkClassifier_4(verbose=True, epoch=10, optimizer=AdaGrad, initializer=HeInitializer, activater=ReLU)\n",
        "SDNN4.fit(x_train, y_train_one_hot, x_val, y_test_one_hot)\n",
        "\n",
        "pred = SDNN4.predict(x_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "-cIj0Nac8zHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN4.epoch+1)), SDNN4.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN4.epoch+1)), SDNN4.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN.epoch+1)));"
      ],
      "metadata": {
        "id": "BRvD7BpeST56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScratchDeepNeuralNetrowkClassifier_6():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20\n",
        "        self.n_features = 784\n",
        "        self.n_nodes1 = 400\n",
        "        self.n_nodes2 = 200\n",
        "        self.n_nodes3 = 150\n",
        "        self.n_nodes4 = 100\n",
        "        self.n_nodes5 = 50\n",
        "        self.n_output = 10\n",
        "        self.sigma = 0.02\n",
        "        self.lr = 0.5\n",
        "        self.epoch = epoch\n",
        "        self.optimizer = optimizer\n",
        "        self.initializer = initializer\n",
        "        self.activater = activater\n",
        "\n",
        "    def fit(self, x, y, x_val=None, y_val=None):\n",
        "        self.loss_train = []\n",
        "        self.loss_val = []\n",
        "        optimizer = self.optimizer(self.lr)\n",
        "\n",
        "        self.FC1 = FC(self.n_features, self.n_nodes1, self.initializer(self.sigma), optimizer)\n",
        "        self.activation1 = self.activater()\n",
        "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, self.initializer(self.sigma), optimizer)\n",
        "        self.activation2 = self.activater()\n",
        "        self.FC3 = FC(self.n_nodes2, self.n_nodes3, self.initializer(self.sigma), optimizer)\n",
        "        self.activation3 = self.activater()\n",
        "        self.FC4 = FC(self.n_nodes3, self.n_nodes4, self.initializer(self.sigma), optimizer)\n",
        "        self.activation4 = self.activater()\n",
        "        self.FC5 = FC(self.n_nodes4, self.n_nodes5, self.initializer(self.sigma), optimizer)\n",
        "        self.activation5 = self.activater()\n",
        "        self.FC6 = FC(self.n_nodes5, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "        self.activation6 = softmax()\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(x, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_x, mini_y in get_mini_batch:\n",
        "                self.forward(mini_x)\n",
        "                self.backward(mini_y)\n",
        "            \n",
        "            if self.verbose:\n",
        "                self.forward(x)\n",
        "                self.loss_train.append(self.activation6.backward(self.Z6, y)[1])\n",
        "\n",
        "                if x_val is not None:\n",
        "                    self.forward(x_val)\n",
        "                    self.loss_val.append(self.activation6.backward(self.Z6, y_val)[1])\n",
        "        \n",
        "        def forward(self, x):\n",
        "                A1 = self.FC1.forward(x)\n",
        "                Z1 = self.activation1.forward(A1)\n",
        "                A2 = self.FC2.forward(Z1)\n",
        "                Z2 = self.activation2.forward(A2)\n",
        "                A3 = self.FC3.forward(Z2)\n",
        "                Z3 = self.activation3.forward(A3)\n",
        "                A4 = self.FC4.forward(Z3)\n",
        "                Z4 = self.activation4.forward(A4)\n",
        "                A5 = self.FC5.forward(Z4)\n",
        "                Z5 = self.activation5.forward(A5)\n",
        "                A6 = self.FC5.forward(Z5)\n",
        "                self.Z6 = self.activation6.forward(A6)\n",
        "\n",
        "    def backward(self,y):\n",
        "                dA6, self.loss = self.activation6.backward(self.Z6, y)\n",
        "                dZ5 = self.FC6.backward(dA6)\n",
        "                dA5 = self.activation5.backward(dZ5)\n",
        "                dZ4 = self.FC5.backward(dA5)\n",
        "                dA4 = self.activation4.backward(dZ4)\n",
        "                dZ3 = self.FC4.backward(dA4)\n",
        "                dA3 = self.activation3.backward(dZ3)\n",
        "                dZ2 = self.FC3.backward(dA3)\n",
        "                dA2 = self.activation2.backward(dZ2)\n",
        "                dZ1 = self.FC2.backward(dA2)\n",
        "                dA1 = self.activation1.backward(dZ1)\n",
        "                dZ0 = self.FC1.backward(dA1)\n",
        "\n",
        "    def predict(self, x):\n",
        "        self.forward(x)\n",
        "        return np.argmax(self.Z6, axis=1)"
      ],
      "metadata": {
        "id": "Z1xuly2bS5f_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SDNN6 = ScratchDeepNeuralNetrowkClassifier_6(verbose=True, epoch=10, optimizer=AdaGrad, initializer=HeInitializer, activater=ReLU)\n",
        "SDNN6.fit(x_train, y_train_one_hot, x_val, y_test_one_hot)\n",
        "\n",
        "pred = SDNN6.predict(x_val)\n",
        "accuracy_score(y_val, pred)"
      ],
      "metadata": {
        "id": "lUcvqqoHWg4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(list(range(1, SDNN6.epoch+1)), SDNN6.loss_train, label='train')\n",
        "plt.plot(list(range(1, SDNN6.epoch+1)), SDNN6.loss_val, label='test')\n",
        "plt.legend()\n",
        "plt.xticks(list(range(1, SDNN6.epoch+1)));"
      ],
      "metadata": {
        "id": "kGxQyT2lWn9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class General_ScratchDeepNeuralNetrowkClassifier():\n",
        "\n",
        "    def __init__(self, verbose=False, epoch=1, optimizer=SGD, initializer=HeInitializer, activater=ReLU, n_nodes=None):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 20\n",
        "        self.sigma = 0.02\n",
        "        self.lr = 0.5\n",
        "        self.epoch = epoch\n",
        "        self.optimizer = optimizer\n",
        "        self.initializer = initializer\n",
        "        self.activater = activater\n",
        "        self.n_nodes = n_nodes\n",
        "\n",
        "    def fit(self, x, y, x_val=None, y_val=None):\n",
        "        self.loss_train = []\n",
        "        self.loss_val = []\n",
        "        optimizer = self.optimizer(self.lr)\n",
        "        self.fcs = []\n",
        "        self.act = []\n",
        "    \n",
        "        for i in range(len(self.n_nodes)-2):\n",
        "            self.fcs.append(FC(self.n_nodes[i], self.n_nodes[i+1], self.initializer(self.sigma), optimizer))\n",
        "            self.act.append(self.activater())\n",
        "        self.fcs.append(FC(self.n_nodes[i+1], self.n_nodes[-1], self.initializer(self.sigma), optimizer))\n",
        "        self.act.append(softmax())  \n",
        "          \n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(x, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_x, mini_y in get_mini_batch:\n",
        "                A = []\n",
        "                Z = []\n",
        "                for i, (f, a) in enumerate(zip(self.fcs, self.act)):\n",
        "                    if i ==0:\n",
        "                        A.append(f.forward(mini_x))\n",
        "                        Z.append(a.forward(A[i]))\n",
        "                    else:\n",
        "                      A.append(f.forward(Z[i-1]))\n",
        "                      Z.append(a.forward(A[i]))\n",
        "                dA = []\n",
        "                dZ = []"
      ],
      "metadata": {
        "id": "8bGh8At4XzZM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}